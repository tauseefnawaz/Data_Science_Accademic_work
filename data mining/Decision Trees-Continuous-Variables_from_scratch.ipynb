{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import scipy.stats\n",
    "from collections import defaultdict  # default dictionary \n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,purity,klasslabel='',score=0,split=[],fidx=-1):\n",
    "        self.lchild=None       \n",
    "        self.rchild=None\n",
    "        self.klasslabel=klasslabel        \n",
    "        self.split=split\n",
    "        self.score=score\n",
    "        self.fidx=fidx\n",
    "        self.purity=purity    \n",
    "        \n",
    "    def set_childs(self,lchild,rchild):\n",
    "        self.lchild=lchild\n",
    "        self.rchild=rchild\n",
    "\n",
    "        \n",
    "    def isleaf(self):\n",
    "        if(self.lchild==None and self.lchild==None):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        # Your Code Here\n",
    "        \n",
    "\n",
    "    def isless_than_eq(self, X):\n",
    "        if (X[self.fidx] < self.split):\n",
    "            return True\n",
    "        return False\n",
    "        # Your Code Here\n",
    "\n",
    "        \n",
    "    def get_str(self):        \n",
    "        if self.isleaf():\n",
    "            return 'C(class={},Purity={})'.format(self.klasslabel,self.purity)\n",
    "        else:\n",
    "            return 'I(Fidx={},Score={},Split={})'.format(self.fidx,self.score,self.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(P1,P2,P3):\n",
    "    if (P1 == 0):\n",
    "        P1 += 0.0000001\n",
    "    if (P2 == 0):\n",
    "        P2 += 0.0000001\n",
    "    if (P3 == 0):\n",
    "        P3 += 0.0000001\n",
    "    return -((P1*np.log2(P1))+(P2*np.log2(P2))+(P3*np.log2(P3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here...7852\n",
    "class DecisionTree:\n",
    "    ''' Implements the Decision Tree For Classification... '''\n",
    "    def __init__(self, purityp, exthreshold,maxdepth=10,tree=None):        \n",
    "        self.purity=purityp\n",
    "        self.exthreshold=exthreshold\n",
    "        self.maxdepth=maxdepth\n",
    "        self.tree=tree\n",
    "        \n",
    "    def train(self, X, Y):\n",
    "        ''' Train Decision Tree using the given \n",
    "            X [m x d] data matrix and Y labels matrix\n",
    "            \n",
    "            Input:\n",
    "            ------\n",
    "            X: [m x d] a data matrix of m d-dimensional examples.\n",
    "            Y: [m x 1] a label vector.\n",
    "            \n",
    "            Returns:\n",
    "            -----------\n",
    "            Nothing\n",
    "            '''\n",
    "        nexamples,nfeatures=X.shape\n",
    "        ## now go and train a model for each class...\n",
    "        # YOUR CODE HERE\n",
    "        self.tree = self.build_tree(X,Y,self.maxdepth)\n",
    "        #self.__str__()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def build_tree(self, X, Y, depth):\n",
    "        \"\"\" \n",
    "            Function is used to recursively build the decision Tree \n",
    "          \n",
    "            Input\n",
    "            -----\n",
    "            X: [m x d] a data matrix of m d-dimensional examples.\n",
    "            Y: [m x 1] a label vector.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            root node of the built tree...\n",
    "        \"\"\"\n",
    "        nexamples, nfeatures=X.shape\n",
    "      \n",
    "        klasses,counts=np.unique(Y,return_counts=True);\n",
    "        # YOUR CODE HERE                \n",
    "        class_purity = counts[np.argmax(counts)]/np.sum(counts)\n",
    "        if(depth==0 or self.purity<=class_purity):\n",
    "            return Node(class_purity, klasses[np.argmax(counts)])\n",
    "        best_split = 0.0\n",
    "        best_score = 0.0\n",
    "        feature = -1\n",
    "        leftIdx = None\n",
    "        rightIdx = None\n",
    "        \n",
    "        # Getting best feature and score\n",
    "        for i in range (0, X.shape[1]):\n",
    "            \n",
    "            split,mingain,Xlidx,Xridx=self.evaluate_numerical_attribute(X[:,i],Y)\n",
    "            \n",
    "            if(mingain > best_score):\n",
    "                best_score = mingain\n",
    "                best_split = split\n",
    "                feature = i\n",
    "                leftIdx = Xlidx\n",
    "                rightIdx = Xridx\n",
    "       \n",
    "        # Recursively calling build_tree on nodes\n",
    "        n = Node(purity=class_purity,klasslabel='', score=best_score, split=best_split, fidx=feature)\n",
    "        \n",
    "        n.lchild = self.build_tree(X[leftIdx], Y[leftIdx], depth-1)\n",
    "        n.rchild = self.build_tree(X[rightIdx], Y[rightIdx], depth-1)\n",
    "        return n\n",
    "        \n",
    "    def test(self, X):\n",
    "        \n",
    "        ''' Test the trained classifiers on the given set of examples \n",
    "        \n",
    "                   \n",
    "            Input:\n",
    "            ------\n",
    "            X: [m x d] a data matrix of m d-dimensional test examples.\n",
    "           \n",
    "            Returns:\n",
    "            -----------\n",
    "                pclass: the predicted class for each example, i.e. to which it belongs\n",
    "        '''\n",
    "        \n",
    "        nexamples, nfeatures=X.shape\n",
    "        pclasses=self.predict(X)\n",
    "        \n",
    "        # your code go here...\n",
    "        \n",
    "    \n",
    "    def evaluate_numerical_attribute(self,feat, Y):\n",
    "        '''\n",
    "            Evaluates the numerical attribute for all possible split points for\n",
    "            possible feature selection\n",
    "            \n",
    "            Input:\n",
    "            ---------\n",
    "            feat: a contiuous feature\n",
    "            Y: labels\n",
    "            \n",
    "            Returns:\n",
    "            ----------\n",
    "            v: splitting threshold\n",
    "            score: splitting score\n",
    "            Xlidx: Index of examples belonging to left child node\n",
    "            Xridx: Index of examples belonging to right child node\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        # A big source of Bugs will be sorting the same array and expecting it to behave original,\n",
    "        # use separate variables to store the sorted array and its corresponding classes labels...\n",
    "        \n",
    "        classes=np.unique(Y)\n",
    "        nclasses=len(classes)\n",
    "        sidx=np.argsort(feat)\n",
    "        f=feat[sidx] # sorted features\n",
    "        sY=Y[sidx] # sorted features class labels...\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        #for i in get_Spliting_values_from_column(feat):\n",
    "        classes,counts = np.unique(Y,return_counts = True)\n",
    "        Target_entropy = 0.0\n",
    "        split = 0.0\n",
    "        score = 0.0\n",
    "        \n",
    "        for count in counts:\n",
    "            Target_entropy +=  -(((count/np.sum(counts))*(math.log2(count/np.sum(counts)))))\n",
    "            \n",
    "        SplitingArray = []\n",
    "        for i in range(len(np.unique(feat))):\n",
    "            SplitingArray.append((np.unique(feat)[i-1]+np.unique(feat)[i])/2)\n",
    "        prev_entropy = 999\n",
    "        for x in SplitingArray:\n",
    "            P1=P2=P3=P4=P5=P6=0\n",
    "            entropy=0.0\n",
    "            for i in range(len(feat)):\n",
    "                if(x<feat[i] and Y[i] == classes[0]):\n",
    "                    P1 += 1\n",
    "                elif(x < feat[i] and Y[i] == classes[1]):\n",
    "                    P2 += 1\n",
    "                elif(x > feat[i] and Y[i] == classes[0]):\n",
    "                    P4 += 1\n",
    "                elif(x > feat[i] and Y[i] == classes[1]):\n",
    "                    P5 += 1\n",
    "                elif(x < feat[i]):\n",
    "                    P3 += 1\n",
    "                elif(x > feat[i]):\n",
    "                    P6 += 1            \n",
    "            if((P1+P2+P3)==0 or (P4+P5+P6) ==0):\n",
    "                continue\n",
    "            entropy = ((((P1+P2+P3)/np.sum(counts))*calculate_entropy(P1/(P1+P2+P3),P2/(P1+P2+P3),P3/(P1+P2+P3)))+(((P4+P5+P6)/np.sum(counts))*calculate_entropy(P4/(P4+P5+P6),P5/(P4+P5+P6),P6/(P4+P5+P6))))\n",
    "            #print(P1,P2,P3,P4,P5,P6,entropy,x)\n",
    "            if(entropy <= prev_entropy):\n",
    "                prev_entropy = entropy\n",
    "                score =(Target_entropy - entropy)\n",
    "                split = x\n",
    "        leftChildInd = np.where(feat <  split)[0]\n",
    "        RightChildInd = np.where(feat > split)[0]\n",
    "        return split, score, leftChildInd, RightChildInd\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        \"\"\"\n",
    "        Test the trained classifiers on the given example X\n",
    "        \n",
    "                   \n",
    "            Input:\n",
    "            ------\n",
    "            X: [1 x d] a d-dimensional test example.\n",
    "           \n",
    "            Returns:\n",
    "            -----------\n",
    "                pclass: the predicted class for the given example, i.e. to which it belongs\n",
    "        \"\"\"\n",
    "       #  # YOUR CODE HERE\n",
    "        pclass = []\n",
    "        for i in range (0, X.shape[0]):\n",
    "            temp = self._predict(self.tree, X[i,:])\n",
    "            pclass.append(temp)\n",
    "        return pclass\n",
    "    \n",
    "    def _predict(self,node, X):\n",
    "        if (node.isleaf() == True):\n",
    "            temp = node.klasslabel\n",
    "            return temp\n",
    "        else:\n",
    "            if (node.isless_than_eq(X) == True):\n",
    "                return self._predict(node.lchild, X)\n",
    "            else:\n",
    "                return self._predict(node.rchild, X)\n",
    "        # YOUR CODE HERE\n",
    "      \n",
    "\n",
    "        \n",
    "\n",
    "    def __str__(self):\n",
    "        \n",
    "        return self.__print(self.tree)        \n",
    "        \n",
    "     \n",
    "    def find_depth(self):\n",
    "        \n",
    "        return self._find_depth(self.tree)\n",
    "    \n",
    "    \n",
    "    def _find_depth(self,node):\n",
    "        if not node:\n",
    "            return\n",
    "        if node.isleaf():\n",
    "            return 1\n",
    "        else:\n",
    "            return max(self._find_depth(node.lchild),self._find_depth(node.rchild))+1\n",
    "        \n",
    "    def __print(self,node,depth=0):\n",
    "        \n",
    "        ret = \"\"\n",
    "\n",
    "        # Print right branch\n",
    "        if node.rchild:\n",
    "            ret += self.__print(node.rchild,depth+1)\n",
    "\n",
    "        # Print own value\n",
    "        \n",
    "        ret += \"\\n\" + (\"    \"*depth) + node.get_str()\n",
    "\n",
    "        # Print left branch\n",
    "        if node.lchild:\n",
    "            ret += self.__print(node.lchild,depth+1)\n",
    "        \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tools as t # set of tools for plotting, data splitting, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "count   149.000000  149.000000   149.000000  149.000000\n",
      "mean      5.848322    3.051007     3.774497    1.205369\n",
      "std       0.828594    0.433499     1.759651    0.761292\n",
      "min       4.300000    2.000000     1.000000    0.100000\n",
      "25%       5.100000    2.800000     1.600000    0.300000\n",
      "50%       5.800000    3.000000     4.400000    1.300000\n",
      "75%       6.400000    3.300000     5.100000    1.800000\n",
      "max       7.900000    4.400000     6.900000    2.500000\n"
     ]
    }
   ],
   "source": [
    "#load the data set\n",
    "data=pd.read_csv('./iris.data')\n",
    "data.columns=['SepalLength','SepalWidth','PetalLength','PetalWidth','Class']\n",
    "print (data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data Set Dimensions= (149, 4)  True Class labels dimensions (149,)\n"
     ]
    }
   ],
   "source": [
    "# Get your data in matrix (X ,Y)\n",
    "X = np.array(data.loc[:, 'SepalLength':'PetalWidth'])\n",
    "Y = np.array(data.loc[:,'Class'])\n",
    "print (\" Data Set Dimensions=\", X.shape, \" True Class labels dimensions\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.9137533408759091\n"
     ]
    }
   ],
   "source": [
    "dt=DecisionTree(0.95,5,2)\n",
    "feat=[0,1]\n",
    "dt.classes=np.unique(Y)\n",
    "dt.nclasses=len(np.unique(Y))\n",
    "split,mingain,Xlidx,Xridx=dt.evaluate_numerical_attribute(X[:,3],Y)\n",
    "print(split,mingain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "2.45 0.9137533408759091 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48] [ 49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66\n",
      "  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102\n",
      " 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n",
      " 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138\n",
      " 139 140 141 142 143 144 145 146 147 148]\n"
     ]
    }
   ],
   "source": [
    "print (len(Y))\n",
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(X, Y)\n",
    "g,s,xl,xr=dt.evaluate_numerical_attribute(X[:,2],Y)\n",
    "print(g, s, xl, xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Data Set Dimensions= (104, 4) Training True Class labels dimensions (104,)\n",
      " Test Data Set Dimensions= (45, 4) Test True Class labels dimensions (104,)\n"
     ]
    }
   ],
   "source": [
    "# Split your data into training and test-set... \n",
    "# see the documentation of split_data in tools for further information...\n",
    "Xtrain,Ytrain,Xtest,Ytest=t.split_data(X,Y)\n",
    "\n",
    "print (\" Training Data Set Dimensions=\", Xtrain.shape, \"Training True Class labels dimensions\", Ytrain.shape)\n",
    "print (\" Test Data Set Dimensions=\", Xtest.shape, \"Test True Class labels dimensions\", Ytrain.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets train a Decision Tree Classifier on Petal Length and Width\n",
    "feat=[0,1]\n",
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets test it on the set of unseen examples...\n",
    "pclasses=dt.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's See How Good we are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "Accuracy =  0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "#Lets see how good we are doing, by finding the accuracy on the test set..\n",
    "print (np.sum(pclasses==Ytest))\n",
    "print (\"Accuracy = \", np.sum(pclasses==Ytest)/float(Ytest.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Train on All 4 Features and all 3 classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Data Set Dimensions= (104, 4) Training True Class labels dimensions (104,)\n",
      " Test Data Set Dimensions= (45, 4) Test True Class labels dimensions (104,)\n"
     ]
    }
   ],
   "source": [
    "# Split your data into training and test-set... \n",
    "# see the documentation of split_data in tools for further information...\n",
    "Xtrain,Ytrain,Xtest,Ytest=t.split_data(X,Y)\n",
    "\n",
    "print (\" Training Data Set Dimensions=\", Xtrain.shape, \"Training True Class labels dimensions\", Ytrain.shape)\n",
    "print (\" Test Data Set Dimensions=\", Xtest.shape, \"Test True Class labels dimensions\", Ytrain.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "Accuracy =  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(Xtrain,Ytrain)\n",
    "pclasses=dt.predict(Xtest)\n",
    "#Lets see how good we are doing, by finding the accuracy on the test set..\n",
    "print (np.sum(pclasses==Ytest))\n",
    "print (\"Accuracy = \", np.sum(pclasses==Ytest)/float(Ytest.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
